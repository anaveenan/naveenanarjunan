{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Simulation to Estimate the Power of an A/B experiment\n",
    "> A tutorial on estimating power of an A/B experiment\n",
    "\n",
    "- toc: false\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [a/b testing, python]\n",
    "- image: images/chart-preview.png\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "This article was originally posted in my medium blog post [here](https://medium.com/analytics-vidhya/using-simulation-to-estimate-the-power-of-an-a-b-experiment-d38adf32b29c)\n",
    "\n",
    "\n",
    "Power of an experiment measures the ability of the experiment to detect a specific alternate hypothesis. For example, an e-commerce company is trying to increase the time users spend on the website by changing the design of the website. They plan to use the well-known two-sample t-test. Power helps in answering the question: will the t-test be able to detect a difference in mean time spend (if it exists) by rejecting the null hypothesis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Lets state the hypothesis   \n",
    "\n",
    "**Null Hypothesis H<sub>0</sub>**: New design has no effect on the time users spend on the website  \n",
    "**Alternate Hypothesis H<sub>a</sub>**: New design impacts the time users spend on the website   \n",
    "\n",
    "\n",
    "\n",
    "When an A/B experiment is run to measure the impact of the website redesign, \n",
    "we want to ensure that the experiment has at least 80% power. The following parameters impact the power of the experiment:  \n",
    "\n",
    "\n",
    "**1. Sample size(n):** Larger the sample size, smaller the standard error becomes; and makes sampling distribution smaller. Increasing the sample size, increases the power of the experiment  \n",
    "**2. Effect size(ùõø):** Difference between the means sampling distribution of null and alternative hypothesis. Smaller the effect size, need more samples to detect an effect at predefined power  \n",
    "**3. Alpha(ùõº):** Significance value is typically set at 0.05; this is the cut off at which we accept or reject our null hypothesis. Making alpha smaller requires more samples to detect an effect at predefined power  \n",
    "**4. Beta(Œ≤):** Power is defined as 1-Œ≤  \n",
    "\n",
    "\n",
    "Why power analysis is done to determine sample size before running an experiment?  \n",
    "\n",
    "1. Running experiments is expensive and time consuming  \n",
    "2. Increases the chance of finding significant effect  \n",
    "3. Increases the chance of replicating an effect detected in an experiment  \n",
    "\n",
    "\n",
    "For example, the time users spend currently on the website is normally distributed with mean 2 minutes and standard deviation 1 minute. The product manager wants to design an experiment to understand if the redesigned website helps in increasing the time spent on the website.  \n",
    "\n",
    "The experiment should be able to detect a minimum of 5% change in time spent on the website. For a test like this, an exact solution is available to estimate sample size since sampling distribution is known. Here we will use the simulation method to estimate the sample and validate the same using exact method.  \n",
    "\n",
    "The following steps estimate the power of two-sample t-test:\n",
    "\n",
    "1. Simulate data for the model under null ùí©(2,1) and alternate hypothesis ùí©(2+ùõø,1)  \n",
    "2. Perform t-test on the sample and record whether the t-test rejects the null hypothesis  \n",
    "3. Run the simulation multiple number of times and count the number of times the t-test rejects the null hypothesis.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to compute power of experiment for a specified sample size, effect size and significance level:  \n",
    "\n",
    "Power of the experiment is 58.8% with sample size of 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power of the experiment 58.8%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "# Initialize delta(minimum lift the product manager expect), control_mean, control_sd\n",
    "delta=0.05\n",
    "control_mean=2\n",
    "control_sd=1\n",
    "sample_size=1000\n",
    "alpha=0.05#significance of the experiment\n",
    "n_sim=1000#Total number of samples to simulate\n",
    "\n",
    "np.random.seed(123)#set seed\n",
    "def simulate_data(control_mean,control_sd,sample_size,n_sim):\n",
    "    # Simulate the time spend under null hypothesis\n",
    "    control_time_spent = np.random.normal(loc=control_mean, scale=control_sd, size=(sample_size,n_sim))\n",
    "    # Simulate the time spend under alternate hypothesis\n",
    "    treatment_time_spent = np.random.normal(loc=control_mean*(1+delta), scale=control_sd, size=(sample_size,n_sim))\n",
    "    return control_time_spent,treatment_time_spent\n",
    "# Run the t-test and get the p_value\n",
    "control_time_spent, treatment_time_spent=simulate_data(control_mean,control_sd,sample_size,n_sim)\n",
    "t_stat, p_value = st.ttest_ind(control_time_spent, treatment_time_spent)\n",
    "power=(p_value<0.05).sum()/n_sim\n",
    "print(\"Power of the experiment {:.1%}\".format(power))\n",
    "#Power of the experiment 58.8%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to compute sample size required to reach 80% power for specified effect size and significance level:  \n",
    "Based on simulation methods we need 1560 users to reach power of 80% and this closely matches with sample size estimated using exact method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum sample size required to reach significance 1560\n"
     ]
    }
   ],
   "source": [
    "#increment sample size till required power is reached \n",
    "sample_size=1000\n",
    "np.random.seed(123)\n",
    "while True:\n",
    "    control_time_spent, treatment_time_spent=simulate_data(control_mean,control_sd,sample_size,n_sim)\n",
    "    t_stat, p_value = st.ttest_ind(control_time_spent, treatment_time_spent)\n",
    "    power=(p_value<alpha).sum()/n_sim\n",
    "    if power>.80:\n",
    "        print(\"Minimum sample size required to reach significance {}\".format(sample_size))\n",
    "        break\n",
    "    else:\n",
    "        sample_size+=10\n",
    "#Minimum sample size required to reach significance 1560"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to compute sample size using exact method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum sample size required to reach significance: 1571\n"
     ]
    }
   ],
   "source": [
    "#Analtyical solution to compute sample size\n",
    "from statsmodels.stats.power import tt_ind_solve_power\n",
    "\n",
    "treat_mean=control_mean*(1+delta)\n",
    "mean_diff=treat_mean-control_mean\n",
    "\n",
    "cohen_d=mean_diff/np.sqrt((control_sd**2+control_sd**2)/2)\n",
    "\n",
    "n = tt_ind_solve_power(effect_size=cohen_d, alpha=alpha, power=0.8, ratio=1, alternative='two-sided')\n",
    "print('Minimum sample size required to reach significance: {:.0f}'.format(round(n)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "This article explained how simulation can be used to estimate power of an A/B experiment when a closed form solution doesn‚Äôt exist."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai] *",
   "language": "python",
   "name": "conda-env-fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
