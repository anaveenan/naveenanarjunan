{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audience Splitting in A/B Experiments\n",
    "> A tutorial on how to split audience in a deterministic way using hashing.\n",
    "\n",
    "- toc: false \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [altair, python]\n",
    "- image: images/chart-preview.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "One key element in running a A/B experiment is splitting of audience based on the unit of diversion. Most of the experiment platforms does the splitting of audience for us. But there are situation in which analyst need to run an A/B experiment and splitting of audience need to performed by the analyst. In most of the organizations data is stored in a database and it would be nice if we can perform treatment assignment in SQL . Also, we need the audience split to perform post-hoc analysis of the experiment. In this blog, I will show how to perform audience splitting in spark and Hive using an example.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Lets create a spark session in local.   \n",
    "2. Lets create a dummy dataset with 100,000 customers along with gender information.  \n",
    "3. Add uuid column to the dataframe to uniquely identify a user.  \n",
    "4. Convert pandas dataframe to a spark dataframe \n",
    "5. Register the spark dataframe as \"user_table\" to be accessed in Hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>gender</th>\n",
       "      <th>user_uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "      <td>817be0d1-067c-41b8-86bc-ef6ab335ff46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>m</td>\n",
       "      <td>afbac2c3-c2ae-413d-9d00-712da8ce5eb2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>m</td>\n",
       "      <td>c8c990fa-7884-4c1d-89e2-d5e8af0a33fe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>m</td>\n",
       "      <td>43fd874f-4644-405a-ae5e-44c01c7d3871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>f</td>\n",
       "      <td>9d78651b-d55f-4d7b-bce7-5d036b95ac6c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user gender                             user_uuid\n",
       "0     0      m  817be0d1-067c-41b8-86bc-ef6ab335ff46\n",
       "1     1      m  afbac2c3-c2ae-413d-9d00-712da8ce5eb2\n",
       "2     2      m  c8c990fa-7884-4c1d-89e2-d5e8af0a33fe\n",
       "3     3      m  43fd874f-4644-405a-ae5e-44c01c7d3871\n",
       "4     4      f  9d78651b-d55f-4d7b-bce7-5d036b95ac6c"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark \n",
    "import altair as alt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import scipy.stats as sc\n",
    "from vega_datasets import data\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "          .builder \\\n",
    "          .enableHiveSupport() \\\n",
    "          .getOrCreate()\n",
    "\n",
    "customers = (pd.DataFrame({'user': np.arange(100000),\n",
    "                      'gender':[np.random.choice(['m','f'], p=[0.55,0.45]) for _ in np.arange(100000)]})\n",
    "         .assign(user_uuid=[uuid.uuid4() for _ in range(100000)])\n",
    "        )\n",
    "\n",
    "customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>gender</th>\n",
       "      <th>user_uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>12d288b0-91e3-471c-849f-38b6e3961a88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>m</td>\n",
       "      <td>b1ea28f2-35fd-4334-92f9-e19fb3cfc924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>f</td>\n",
       "      <td>e636cd3d-6182-4ee0-98d9-bed9350c996d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>f</td>\n",
       "      <td>5f053ff3-5965-4114-808e-636e83c22647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>f</td>\n",
       "      <td>f32af45d-36ff-4996-9704-99f9143a03de</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user gender                             user_uuid\n",
       "0    0      f  12d288b0-91e3-471c-849f-38b6e3961a88\n",
       "1    1      m  b1ea28f2-35fd-4334-92f9-e19fb3cfc924\n",
       "2    2      f  e636cd3d-6182-4ee0-98d9-bed9350c996d\n",
       "3    3      f  5f053ff3-5965-4114-808e-636e83c22647\n",
       "4    4      f  f32af45d-36ff-4996-9704-99f9143a03de"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf=spark.createDataFrame(customers.astype(str))\n",
    "sdf.createOrReplaceTempView(\"user_table\") \n",
    "sdf.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audience splitting \n",
    "> Cool hashing trick to perform audience splitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Select the unit of diversion key : user_uuid in our case (or the ID field we want to split on).  \n",
    "2. And a salt('new_widget' in our example), unique value to identify our experiment.  \n",
    "3. Concatenate car_uuid with the salt selected.  \n",
    "4. Apply a hashing algorithm like md5 hash to split audience into treatment and control "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"\"\"select \n",
    "user_uuid,\n",
    "if(\n",
    "   conv(\n",
    "      substr(\n",
    "          md5(concat(user_uuid, '-','new_widget')),\n",
    "          1, 6),\n",
    "      16,10)/conv('ffffff',16,10) > 0.50, 'treatment', 'control') as treatment\n",
    ",gender\n",
    "from user_table\n",
    "\"\"\"\n",
    "df_audience=spark.sql(query).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation of assignment \n",
    "> Chi-Square test of indepence is our friend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets visualize the split and looks like assignment is 50-50. But how do we validate this with statistically rigor ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_8e299cf4_7168_11ea_b918_645aede9f057\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >treatment</th>        <th class=\"col_heading level0 col1\" >users</th>        <th class=\"col_heading level0 col2\" >percent_users</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_8e299cf4_7168_11ea_b918_645aede9f057level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_8e299cf4_7168_11ea_b918_645aede9f057row0_col0\" class=\"data row0 col0\" >control</td>\n",
       "                        <td id=\"T_8e299cf4_7168_11ea_b918_645aede9f057row0_col1\" class=\"data row0 col1\" >50180</td>\n",
       "                        <td id=\"T_8e299cf4_7168_11ea_b918_645aede9f057row0_col2\" class=\"data row0 col2\" >50.18%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_8e299cf4_7168_11ea_b918_645aede9f057level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_8e299cf4_7168_11ea_b918_645aede9f057row1_col0\" class=\"data row1 col0\" >treatment</td>\n",
       "                        <td id=\"T_8e299cf4_7168_11ea_b918_645aede9f057row1_col1\" class=\"data row1 col1\" >49820</td>\n",
       "                        <td id=\"T_8e299cf4_7168_11ea_b918_645aede9f057row1_col2\" class=\"data row1 col2\" >49.82%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x12414f750>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_audience\n",
    " .groupby('treatment')\n",
    " .agg(users=('user_uuid','count'))\n",
    " .reset_index()\n",
    " .assign(percent_users=lambda x:(x['users']/x['users'].sum())*100)\n",
    " .style.format({'percent_users':'{0:.2f}%'.format})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to validate this is see if distribution of gender is random across treatment and control. This can be translated in to a chi square test with the following hypothesis:   \n",
    "\n",
    "  **Null Hypothesis H<sub>0</sub>**: Gender is independent of treatment assignment  \n",
    "  **Alternate Hypothesis H<sub>a</sub>**: Gender is not independent of treatment assignment    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run an chi-square test. P-value of 0.14 indicates we can't reject the null hypothesis - gender is independent of the treatment assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value is 0.14426225571462634\n"
     ]
    }
   ],
   "source": [
    "chi2, p, dof, expected=sc.chi2_contingency(pd.crosstab(df_audience.treatment,\n",
    "                                                       df_audience.gender,\n",
    "                                                       values=df_audience.user_uuid,\n",
    "                                                       aggfunc='count'))\n",
    "print (\"p-value is {}\".format(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion \n",
    "\n",
    "Hashing is very useful technique to assign users to treatment and control in a deterministic way. Using the user_uuid and salt we can get the experiment assignment back. This can also be done easily in any SQL database \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai] *",
   "language": "python",
   "name": "conda-env-fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
